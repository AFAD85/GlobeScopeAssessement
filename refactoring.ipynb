{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    Probeer je oplossing zo te schrijven dat je probeert delen van de code her te gebruiken in plaats van alles opnieuw te doen.\n",
    "    Probeer zo weinig mogelijk indendatie in je code te zetten omdat je voor iedere extra if-statement of for-loop moet onthouden wat er nou precies gebeurt\n",
    "    Het parsen van de input en het verwerken ervan gebeurt nu bij beide direct bij elkaar, bij voorkeur splitsten naar 2 losse plekken (2 losse bestanden bij voorkeur)\n",
    "    Welk zoekalgoritme wordt er gebruikt (naam, beschrijving)? Waarom wordt dat algoritme gebruikt? Indien mogelijk, algoritme opsplitsen van de code voor het probleemdomein en (algoritme liefst maar 1x implementeren en dan hergebruiken)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refactoring:\n",
    "\n",
    "1\n",
    "write the code in a way that prevents reuse:\n",
    "- find all routes is now split between max stops and max distance, will combine the two\n",
    "\n",
    "\n",
    "2\n",
    "avoid using too much indentation such as if and for loops where somebody reading needs to remember a lot to grasp the function\n",
    "- go through code and simplify where possible, where possible will split up functions to increase readability\n",
    "\n",
    "\n",
    "3\n",
    "parsing the input and processing is done in the same file split these to different files\n",
    "Will split the code to have : one file for the route finder and another (main) to run the code\n",
    "\n",
    "\n",
    "4\n",
    "which search algoritm (name/description)is being used\n",
    "- depth first search, goes as deep as possible into the route, in other words, takes the first edge in each nodes till end is reached, then goes back through the visited nodes to look for alternate options. \n",
    "\n",
    "why is this one being used?\n",
    "- I considered this to be the best option as it allows scaling the problem. If the amount of nodes would increase the algoritm would be much more efficient than a BFS (breath first) algoritm. Similarly it is more memory efficient, which would be an issue aswell in a larger graph. \n",
    "In a larger graph BFS would have to keep many (n to the n'th) routes in memory. Which would quickly spiral out of control.\n",
    "Ofcourse we are also always searching for a specific end node, which is also more fitting for DFS over BFS.\n",
    "\n",
    "split the algoritm from the issue at hand \n",
    "- unsure if this is possible in a sensible way. Will attempt while refactoring for point 1. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
